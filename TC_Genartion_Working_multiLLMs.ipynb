{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7c30cb-7f36-4496-ae04-e5d2af1fa4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4071f4e5-fd6d-4004-ae00-7649b880defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file_path = \"Three_EPS_Req.csv\"\n",
    "\n",
    "def load_csv(file_path):\n",
    "    requirements = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            requirements.append(row)\n",
    "    return requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f1d2ac1-4db0-4e61-bf77-55d8ddfab76d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '245112',\n",
       "  'Primary Text': 'Power Supply',\n",
       "  'Artifact Type': 'Heading',\n",
       "  'Safety': '',\n",
       "  'Verification_Criteria': '',\n",
       "  'isHeading': 'TRUE'},\n",
       " {'id': '245113',\n",
       "  'Primary Text': \"The Steering ECU shall ensure reliable operation within the specified voltage range of the vehicle electrical system while maintaining efficient power consumption under varying load conditions.\\nOperating Range:\\n• The Steering ECU shall operate on a 12V or 48V vehicle electrical system, with the following considerations:\\n    '- Nominal Voltage: 12V system.\\n    '- Operating Voltage Range: 10V to 24V.\\n• The ECU shall handle voltage fluctuations within this range without degradation in functionality or performance.\",\n",
       "  'Artifact Type': 'SYS Requirement',\n",
       "  'Safety': 'ASIL A',\n",
       "  'Verification_Criteria': 'The Steering ECU shall monitor its power supply and generate the following Diagnostic Trouble Codes (DTCs) when specific fault conditions occur: \\no Trigger DTC_Voltage_Failure if the supply voltage drops below 10V or exceeds 24V for more than 2 seconds.\\no Indicates a voltage out-of-range condition that could compromise ECU functionality.\\n\\nif the voltage fault clears, the DTC should also clear from ECU fault memory. ',\n",
       "  'isHeading': 'FALSE'},\n",
       " {'id': '245114',\n",
       "  'Primary Text': 'The ECU shall have a maximum power consumption of 50W during peak load conditions (e.g., full steering assist torque at low vehicle speeds).\\n\\nDuring normal operation, power consumption shall not exceed 20W, optimizing energy usage under typical driving conditions.',\n",
       "  'Artifact Type': 'SYS Requirement',\n",
       "  'Safety': 'ASIL A',\n",
       "  'Verification_Criteria': \"Trigger DTC_OverCurrent DTC if power consumption exceeds 50W for more than 1 second under normal operating conditions.\\n'- Indicates an overcurrent condition that could lead to potential ECU overheating or power inefficiency.\\n- if the fault heals, the DTC should also clear from ECU fault memory. \",\n",
       "  'isHeading': ''}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements_doc = load_csv(csv_file_path)\n",
    "requirements_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf7845f5-a70a-4911-ae63-665ff47e4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Specify the path to the PDF file\n",
    "pdf_path = \"EPS_Info.pdf\"\n",
    "\n",
    "# Create a PdfReader object\n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "# Initialize a variable to store the text\n",
    "pdf_text = \"\"\n",
    "\n",
    "# Iterate through all pages and extract text\n",
    "for page in reader.pages:\n",
    "    pdf_text += page.extract_text()\n",
    "\n",
    "# Print the extracted text\n",
    "# print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04db9f3-c66a-4110-881c-981d6c604a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "\n",
    "requirement_texts = text_splitter.create_documents([pdf_text])\n",
    "# sections = text_splitter.split_documents(texts)\n",
    "\n",
    "# for i, section in enumerate(sections):\n",
    "#     print(f\"Section {i + 1}:\\n{section}\\n{'-' * 80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0a892dd-5ce9-4096-8a79-173277238cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [(Document(page_content=str( {\n",
    "            \"Primary Text\": item['Primary Text'],\n",
    "            \"Verification_Criteria\": item['Verification_Criteria'],\n",
    "        }), metadata={\"Requirement ID\": item[\"id\"]})) for item in requirements_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b96e87be-7558-432b-a9d3-bab817eaee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import uuid\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ids = [str(uuid.uuid4()) for _ in range(len(documents))] \n",
    "\n",
    "# unique_collection_name = f\"collection_{uuid.uuid4()}\"\n",
    "\n",
    "# client = Chroma(collection_name=unique_collection_name, embedding_function=embeddings_model)\n",
    "\n",
    "# # Add documents\n",
    "# vector_doc = client.add_documents(documents=documents, ids = ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "317f9f89-129b-4a37-8388-5d4c0efb99fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database saved in: chromadb_store\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "ids = [str(uuid.uuid4()) for _ in range(len(requirement_texts))] \n",
    "\n",
    "unique_collection_name = f\"collection_{uuid.uuid4()}\"\n",
    "\n",
    "persist_directory = \"chromadb_store\"\n",
    "vectorstore = Chroma.from_documents(requirement_texts, collection_name=unique_collection_name, embedding=embeddings_model, persist_directory=persist_directory)\n",
    "\n",
    "print(f\"Vector database saved in: {persist_directory}\")\n",
    "\n",
    "# Add documents\n",
    "#client.add_documents(documents=requirement_texts, ids = ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e73bd0f9-5aaf-4ac6-b8c5-4c88c69f4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "def extract_xml(text: str, tag: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the content of the specified XML tag from the given text. Used for parsing structured responses \n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing the XML.\n",
    "        tag (str): The XML tag to extract content from.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the specified XML tag, or an empty string if the tag is not found.\n",
    "    \"\"\"\n",
    "    match = re.search(f'<{tag}>(.*?)</{tag}>', text, re.DOTALL)\n",
    "    return match.group(1) if match else \"\"\n",
    "\n",
    "# retrieving the relevant documents from vector store\n",
    "def retrieve_documents(query_text, top_k=4):\n",
    "    \"\"\"Fetching relevant document from vector store \"\"\"\n",
    "\n",
    "    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings_model)\n",
    "    \n",
    "    retriever = vectorstore.as_retriever()\n",
    "    retrieve_doc = retriever.invoke(query_text)\n",
    "    \n",
    "    # for item in retrieve_doc:\n",
    "    #      documents.append({\n",
    "    #             \"content\": item.page_content,\n",
    "    #             \"source\": item.metadata,\n",
    "    #         })  \n",
    "    \n",
    "    return retrieve_doc\n",
    "\n",
    "#cleanising the retrieved vector store document\n",
    "def clean_text(relevant_document):\n",
    "    content_list = []\n",
    "    for item in relevant_document:\n",
    "        # Clean the 'content' field\n",
    "        content = item['content']\n",
    "        content = content.replace(\"'\", '\"')\n",
    "        content = re.sub(r'[\\'\\-•]\"\"', \"\", content)  # Remove specified characters\n",
    "        content = re.sub(r'\\s{2,}', ' ', content).strip()  # Normalize whitespace and trim\n",
    "        item['content'] = content\n",
    "        content_list.append(content)\n",
    "        cleanised_document = ''.join(content_list)\n",
    "    return cleanised_document\n",
    "\n",
    "def llm_call_orches(prompt: str, system_prompt: str = \"\", model=\"deepseek-r1-distill-llama-70b\") -> str:\n",
    "    \"\"\"\n",
    "    Calls the model with the given prompt and returns the response.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt to send to the model.\n",
    "        model (str, optional): The model to use for the call. Defaults to \"llama3-70b-8192\".\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the language model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    memory = ConversationBufferWindowMemory(k=10)\n",
    "    \n",
    "    llm = ChatGroq(\n",
    "    model=model,\n",
    "    temperature=0,\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    conversation = ConversationChain(\n",
    "                    llm=llm,\n",
    "                    memory=memory\n",
    "    )\n",
    "    response = conversation.invoke(prompt)\n",
    "    #print(response)\n",
    "    memory.save_context({\"input\": prompt}, {\"response\": response['response']})\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e17535f-b165-4d59-b1f7-353a7b8d1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "from pprint import pprint\n",
    "    \n",
    "class Orchestrator:\n",
    "    \"\"\"Break down tasks and run them in parallel using worker LLMs.\"\"\"\n",
    "    \n",
    "    def __init__(self,orchestrator_prompt: str):\n",
    "        self.orchestrator_prompt = orchestrator_prompt\n",
    "\n",
    "    def _format_prompt(self, template: str,  **kwargs) -> str:\n",
    "        \"\"\"Format a prompt template with variables.\"\"\"\n",
    "        try:\n",
    "            return template.format(**kwargs)\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Missing required prompt variable: {e}\")\n",
    "\n",
    "    def process_llm(self, requirement: str, count: int) -> Dict:\n",
    "        \"\"\"Orchestrate tasks using the LLM based on the given requirement.\n",
    "        \n",
    "        Args:\n",
    "            requirement (str): The requirement to process.\n",
    "        \n",
    "        Returns:\n",
    "            str: Output from the orchestrator.\n",
    "        \"\"\"\n",
    "        unpack = {}\n",
    "        \n",
    "        # retrieving and cleansing the document\n",
    "        raw_documents = retrieve_documents(requirement)\n",
    "        #documents = clean_text(raw_documents)\n",
    "        \n",
    "        if (count>0): \n",
    "            self.orchestrator_prompt = (f\"{ORCHESTRATOR_PROMPT_MEMORY}\")\n",
    "            print(\"************ Understanding Requirement Again **************\")\n",
    "                        \n",
    "        orchestrator_input = self._format_prompt(\n",
    "            self.orchestrator_prompt,\n",
    "            requirement=requirement,\n",
    "            documents=raw_documents,\n",
    "            **unpack\n",
    "        )\n",
    "        orchestrator_response = llm_call_orches(orchestrator_input)\n",
    "        #pprint(orchestrator_response)\n",
    "        \n",
    "        #analysis = extract_xml(orchestrator_response['response'], \"think\")\n",
    "        #test_scenarios = extract_xml(orchestrator_response['response'], \"tests\")\n",
    "        \n",
    "        print(\"\\n=== ORCHESTRATOR OUTPUT ===\")\n",
    "        # pprint(orchestrator_response)\n",
    "        print(f\"\\nANALYSIS:\\n{orchestrator_response['response']}\")\n",
    "        #print(f\"\\nTEST SCENARIOS:\\n{test_scenarios}\")\n",
    "        \n",
    "        return orchestrator_response['response']\n",
    "        #return {\"Analysis\": analysis, \"Test Scenarios\": test_scenarios}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "857322d1-dbc1-4702-a6d3-f91ee7dde532",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PROMPT = \"\"\" You are provided with requirements of Automotive Electronic Control Unit(ECU). \n",
    "Analyze the requirement and understand the context of the it based on documents provided. You should understand the requirement completely.\n",
    "        requirement: {requirement}\n",
    "        documents: {documents}\n",
    "\n",
    "Generate test scenarios to validate the requirement. if you have any doubt please ask for clarifications and don't generate test scenarios\n",
    "\"\"\"\n",
    "\n",
    "WORKER_PROMPT = \"\"\" You are a test case generation assistant who will create test cases for given Test Scenarios. You are well aware of software testing and its testing techniques.\n",
    "Requirement context is given to you as input, your task is to understand the requirement context and generate the test cases with different testing techniques in order to achieve maximum test coverage of requirement.\n",
    "\n",
    "Requirements context:{context_requirement} \n",
    "\n",
    "Output your answer concisely in the following format, with \"NO PREMABLE\": \n",
    "\n",
    "<thoughts>\n",
    "[Your understanding of the requirement and how you planned to write test cases]\n",
    "</thoughts>\n",
    "\n",
    "<test_cases>\n",
    "Test Case ID : ID for test case (should be whole number)\n",
    "Objective : Objective of test case\n",
    "Test Design Technique : Test design technique used for this test\n",
    "Pre-conditions : What are the preconditions before performing the test\n",
    "Post-conditions:  What are the post conditions after performing the test\n",
    "Steps to Execute : Detailed test steps\n",
    "Expected Results : Expected outcome for test step\n",
    "</test_cases>\n",
    "\n",
    "Note: Measure that test case ID should be only integer number and not decimal numbers.\n",
    "\"\"\"\n",
    "\n",
    "EVAL_PROMPT = \"\"\" You are expert in software testing and well aware testing standards. You are provided with certain test cases and its corresponding requirement context \n",
    "Your task is to evaluate:\n",
    "- Whether the test cases achieve the maximum coverage for input requirement context.\n",
    "- Whether the test cases are written as per standard testing guidelines.\n",
    "- Whether the test steps and expected results are clear and concise\n",
    "\n",
    "Output \"PASS\" only if you don't have any further improvement points based on above evaluations.\n",
    "Output \"SATISFACTORY\" if the test cases satisfy the above evaluations.\n",
    "\n",
    "Note: You should evaluate and specify improvement points only based on requirement context and provided criteria, don't makeup your own answer.\n",
    "\n",
    "Output your evaluation concisely in the following format.\n",
    "<evaluation>\n",
    "Feedback level: PASS, SATISFACTORY, NEEDS_IMPROVEMENT, or FAIL.\n",
    "Explain you plan to evaluate the test cases and your understanding of requirement context\n",
    "</evaluation>\n",
    "\n",
    "<feedback>\n",
    "Evaulate and provide the improvement points for test cases, if any. Please be specific. Mention if more test cases needs to be generated along with test sceanrios.\n",
    "</feedback>\n",
    "\n",
    "Here are the inputs you need to perform task on\n",
    "Requirement Context: {Understanding}\n",
    "Test cases to evaluate: {test_cases}\n",
    "\"\"\"\n",
    "\n",
    "FEEDBACK_PROMPT_WORKER = \"\"\" Based on the provided feedback Rewrite the test cases and Output the response in below format. \n",
    "Note: While generating new test cases based on feedback, include the previous test cases also.\n",
    "\n",
    "<thoughts>\n",
    "[Your understanding of the feedback and how you plan to improve]\n",
    "</thoughts>\n",
    "\n",
    "<test_cases>\n",
    "Test Case ID : ID for test case (should be whole number)\n",
    "Objective : Objective of test case\n",
    "Test Design Technique : Test design technique used for this test\n",
    "Pre-conditions : What are the preconditions before performing the test\n",
    "Post-conditions:  What are the post conditions after performing the test\n",
    "Steps to Execute : Detailed test steps\n",
    "Expected Results : Expected outcome for test step \n",
    "</test_cases>\n",
    "\"\"\"\n",
    "FEEDBACK_PROMPT_EVAL = \"\"\" Based on the provide feedback, the test cases has been modified. Please evaluate again.\n",
    "\n",
    "Output \"PASS\" if the test cases satisfy the above evaluations completely.\n",
    "\n",
    "Output your evaluation concisely in the following format.\n",
    "<evaluation\n",
    "PASS, SATISFACTORY, NEEDS_IMPROVEMENT, or FAIL.\n",
    "</evaluation>\n",
    "\n",
    "<feedback>\n",
    "Evaulate and provide the improvement points for test cases, if any. Please be specific.\n",
    "Specify if more test cases needs to be generated along with test sceanrios.\n",
    "</feedback>\n",
    "\"\"\"\n",
    "ORCHESTRATOR_PROMPT_MEMORY = \"\"\"Now Understand these requirements and provide the response.\n",
    "requirement: {requirement}\n",
    "documents: {documents}\n",
    "\n",
    "Return your response in this format:\n",
    "\n",
    "<analysis>\n",
    "Explain your understanding of the given requirement in detail. Break down it in detail. Don't include any \"PREAMBLE\"\n",
    "</analysis>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ecfc180-ef5e-4518-ad68-9b0fcb6d242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_req = requirements_doc[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae4bd9de-fff1-4e57-b76e-61e6fdf527c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Understanding context of Requirement 245113 and generating Test scenarios to validate requirement **************\n",
      "\n",
      "=== ORCHESTRATOR OUTPUT ===\n",
      "\n",
      "ANALYSIS:\n",
      "<think>\n",
      "Okay, so I need to generate test scenarios to validate the given requirement for the Steering ECU. The requirement is that the ECU must operate reliably within a specified voltage range while maintaining efficient power consumption under varying loads. The operating range is 10V to 24V for a 12V nominal system, and it should handle fluctuations without any degradation.\n",
      "\n",
      "First, I should understand what each part of the requirement entails. The ECU needs to work reliably, which means it shouldn't malfunction or have errors when the voltage is within the specified range. It also needs to maintain efficient power consumption, so even when the voltage changes, the ECU shouldn't draw more power than necessary, which could drain the vehicle's battery or cause overheating.\n",
      "\n",
      "The operating voltage range is from 10V to 24V. That's a pretty wide range, so the ECU must be robust enough to handle both lower and higher voltages than the nominal 12V. Voltage fluctuations could be due to various factors like the alternator charging, load changes, or even faults in the electrical system.\n",
      "\n",
      "Now, thinking about test scenarios. I need to cover different aspects: functionality, power consumption, and performance under varying conditions.\n",
      "\n",
      "1. **Nominal Voltage Test**: This is straightforward. Test the ECU at 12V to ensure it operates correctly. This is the baseline to compare other tests against.\n",
      "\n",
      "2. **Minimum Voltage Test**: Test at 10V to see if the ECU still functions without issues. This checks the lower boundary of the operating range.\n",
      "\n",
      "3. **Maximum Voltage Test**: Similarly, test at 24V to ensure the ECU can handle the higher end without malfunctioning.\n",
      "\n",
      "4. **Voltage Fluctuation Test**: This would involve varying the voltage between 10V and 24V in different patterns—maybe slow, fast, random—to simulate real-world conditions. The ECU should handle these changes smoothly without any performance degradation.\n",
      "\n",
      "5. **Power Consumption Test**: Measure the current draw at different voltages (10V, 12V, 24V) to ensure it's efficient across the range. This could involve measuring under both low and high load conditions to see if power consumption remains optimal.\n",
      "\n",
      "6. **Load Variation Test**: Apply varying loads on the ECU while keeping the voltage within the range. This tests if the ECU can handle different workloads without affecting its power consumption efficiency.\n",
      "\n",
      "7. **Transient Voltage Test**: Apply sudden voltage spikes or drops within the range to check if the ECU can handle transient conditions without resetting or malfunctioning.\n",
      "\n",
      "8. **Long-Duration Test**: Run the ECU for an extended period at different voltages to ensure there's no degradation over time. This could help identify any issues related to heat buildup or component stress.\n",
      "\n",
      "9. **Edge Case Test**: Test the ECU just above and below the specified range (like 9.5V and 24.5V) to ensure it gracefully handles voltages outside the range, perhaps by shutting down or entering a safe mode.\n",
      "\n",
      "10. **Environmental Test**: Test the ECU under different environmental conditions (temperature, humidity) while varying the voltage to see if external factors affect its voltage handling and power consumption.\n",
      "\n",
      "Wait, but I'm not sure if the ECU has specific power saving modes or if it's supposed to log any errors when voltage is out of range. Also, how exactly is \"efficient power consumption\" defined? Is there a maximum current draw specified at different voltages? Without knowing the exact power consumption parameters, it might be hard to set pass/fail criteria for the power consumption tests.\n",
      "\n",
      "Additionally, I'm not certain about the acceptable thresholds for voltage fluctuations. How much fluctuation is considered normal, and what's the expected response time of the ECU to these changes? Are there any specific performance metrics, like response time or accuracy, that need to be maintained during voltage variations?\n",
      "\n",
      "Clarifying these points would help in designing more precise test scenarios. For example, knowing the maximum allowable current at 10V and 24V would allow me to set clear benchmarks for the power consumption tests. Similarly, understanding the ECU's expected behavior during voltage spikes or drops would help in defining the test parameters for transient conditions.\n",
      "\n",
      "In summary, while I can outline the general test scenarios, without specific details on power consumption limits and voltage fluctuation handling, the tests might not cover all critical aspects or might not have clear pass/fail criteria.\n",
      "</think>\n",
      "\n",
      "To effectively validate the Steering ECU's requirement, the following structured approach is proposed, along with clarifications needed to ensure comprehensive testing:\n",
      "\n",
      "### Test Scenarios and Clarifications\n",
      "\n",
      "1. **Nominal Voltage Test**\n",
      "   - **Objective**: Verify ECU functionality at 12V.\n",
      "   - **Clarification Needed**: Are there specific performance metrics to measure at nominal voltage?\n",
      "\n",
      "2. **Minimum Voltage Test**\n",
      "   - **Objective**: Ensure ECU operates correctly at 10V.\n",
      "   - **Clarification Needed**: What constitutes acceptable performance at minimum voltage?\n",
      "\n",
      "3. **Maximum Voltage Test**\n",
      "   - **Objective**: Test ECU functionality at 24V.\n",
      "   - **Clarification Needed**: Are there specific functions to test at maximum voltage?\n",
      "\n",
      "4. **Voltage Fluctuation Test**\n",
      "   - **Objective**: Assess ECU performance during voltage changes between 10V and 24V.\n",
      "   - **Clarification Needed**: What are the acceptable rates and patterns of voltage fluctuation?\n",
      "\n",
      "5. **Power Consumption Test**\n",
      "   - **Objective**: Measure current draw at 10V, 12V, and 24V under varying loads.\n",
      "   - **Clarification Needed**: What are the maximum allowable current levels at each voltage?\n",
      "\n",
      "6. **Load Variation Test**\n",
      "   - **Objective**: Evaluate ECU efficiency under different workloads.\n",
      "   - **Clarification Needed**: Define the range of load conditions to test.\n",
      "\n",
      "7. **Transient Voltage Test**\n",
      "   - **Objective**: Test ECU response to sudden voltage spikes or drops.\n",
      "   - **Clarification Needed**: What are the expected responses to transients?\n",
      "\n",
      "8. **Long-Duration Test**\n",
      "   - **Objective**: Ensure ECU reliability over extended operation.\n",
      "   - **Clarification Needed**: What are the criteria for acceptable performance over time?\n",
      "\n",
      "9. **Edge Case Test**\n",
      "   - **Objective**: Test ECU behavior beyond specified voltage range.\n",
      "   - **Clarification Needed**: What is the expected behavior when voltage is out of range?\n",
      "\n",
      "10. **Environmental Test**\n",
      "    - **Objective**: Assess ECU performance under various environmental conditions.\n",
      "    - **Clarification Needed**: What environmental factors need to be considered?\n",
      "\n",
      "### Summary of Clarifications Needed\n",
      "\n",
      "- **Power Consumption Limits**: Specific current draw limits at different voltages.\n",
      "- **Voltage Fluctuation Handling**: Acceptable rates and patterns of voltage changes.\n",
      "- **Performance Metrics**: Definitions of acceptable performance and error logging.\n",
      "- **Transient Response**: Expected ECU behavior during voltage spikes or drops.\n",
      "\n",
      "By addressing these clarifications, the test scenarios can be refined to ensure thorough validation of the ECU's requirements.\n",
      "*********** Understanding context of Requirement 245114 and generating Test scenarios to validate requirement **************\n",
      "\n",
      "=== ORCHESTRATOR OUTPUT ===\n",
      "\n",
      "ANALYSIS:\n",
      "<think>\n",
      "Okay, so I need to generate test scenarios to validate the ECU power consumption requirement. The requirement says that during peak load, like when the steering is assisting fully at low speeds, the ECU shouldn't use more than 50W. Under normal driving conditions, it should stay below 20W. \n",
      "\n",
      "First, I should figure out what \"peak load conditions\" and \"normal operation\" really mean. Peak load is when the ECU is working its hardest, maybe when the car is moving slowly and the steering is being used a lot. Normal operation is everyday driving, where the ECU isn't under as much stress.\n",
      "\n",
      "I need to know what parameters define these conditions. For peak load, maybe it's when the vehicle speed is low, like in a parking lot, and the steering torque is at maximum. For normal operation, it's probably average driving speeds with typical steering use.\n",
      "\n",
      "Next, I should think about how to measure the power consumption. Do we have the right tools? Maybe an ammeter or a power meter that can accurately measure the ECU's power draw under different conditions.\n",
      "\n",
      "I also need to consider how to simulate these conditions. For peak load, maybe we can set up a test where the ECU is operating the steering system at full torque while the vehicle is moving slowly. For normal operation, a standard driving cycle that mimics typical usage would work.\n",
      "\n",
      "I wonder if there are any specific test procedures or standards we should follow. Maybe the company has existing protocols for testing ECUs under various loads. It would be good to align the test scenarios with those to ensure consistency.\n",
      "\n",
      "Another thing to consider is the environment. Should these tests be conducted in a controlled lab setting or on an actual vehicle? Lab testing might be more precise, but real-world testing could reveal unexpected factors.\n",
      "\n",
      "I also need to define what constitutes a pass or fail. If the ECU's power consumption exceeds 50W during peak load or 20W during normal operation, that's a fail. But what's the margin? Is it a hard limit, or is there some tolerance?\n",
      "\n",
      "Lastly, I should think about how to document the test results. Clear data logging will be essential to verify the ECU's performance and ensure it meets the requirements.\n",
      "\n",
      "I think I've covered the main points, but I'm still a bit unsure about the exact parameters for peak and normal conditions. Maybe I should ask for more details on vehicle speed and steering torque levels to make the test scenarios more precise.\n",
      "</think>\n",
      "\n",
      "To validate the ECU power consumption requirement, the following structured approach is proposed:\n",
      "\n",
      "### Test Scenarios for ECU Power Consumption Validation\n",
      "\n",
      "1. **Peak Load Conditions:**\n",
      "   - **Definition:** Full steering assist torque at low vehicle speeds (e.g., parking lot maneuvers).\n",
      "   - **Parameters:** \n",
      "     - Vehicle Speed: Low (e.g., 5-10 km/h).\n",
      "     - Steering Torque: Maximum assist level.\n",
      "   - **Measurement:** Use an ammeter or power meter to measure ECU power draw.\n",
      "   - **Simulation:** Set up a test where the ECU operates the steering system at full torque while the vehicle moves slowly.\n",
      "   - **Environment:** Conduct in a controlled lab setting for precision, with consideration for real-world testing to capture unexpected factors.\n",
      "\n",
      "2. **Normal Operation Conditions:**\n",
      "   - **Definition:** Typical everyday driving with average steering use.\n",
      "   - **Parameters:** \n",
      "     - Vehicle Speed: Average driving speeds (e.g., 40-60 km/h).\n",
      "     - Steering Torque: Typical, moderate levels.\n",
      "   - **Measurement:** Use an ammeter or power meter to measure ECU power draw.\n",
      "   - **Simulation:** Implement a standard driving cycle that mimics typical usage patterns.\n",
      "\n",
      "3. **Test Procedures and Standards:**\n",
      "   - Align with existing company protocols for ECU testing to ensure consistency and reliability.\n",
      "\n",
      "4. **Pass/Fail Criteria:**\n",
      "   - **Peak Load:** Power consumption must not exceed 50W. A hard limit with no tolerance.\n",
      "   - **Normal Operation:** Power consumption must not exceed 20W. A hard limit with no tolerance.\n",
      "\n",
      "5. **Documentation:**\n",
      "   - Maintain clear and detailed data logs to verify ECU performance and compliance with requirements.\n",
      "\n",
      "### Considerations and Next Steps:\n",
      "- Clarify exact parameters for peak and normal conditions, including specific vehicle speeds and steering torque levels.\n",
      "- Ensure the use of appropriate measurement tools and environments for accurate testing.\n",
      "\n",
      "This structured approach ensures comprehensive validation of the ECU's power consumption under both peak and normal conditions, adhering to defined requirements and testing standards.\n"
     ]
    }
   ],
   "source": [
    "orchestrator = Orchestrator(\n",
    "    orchestrator_prompt=ORCHESTRATOR_PROMPT\n",
    ")\n",
    "requirement_count=0\n",
    "for item in requirements_doc:\n",
    "    if item['Artifact Type'] == 'SYS Requirement':\n",
    "        print(f\"*********** Understanding context of Requirement {item['id']} and generating Test scenarios to validate requirement **************\")\n",
    "        result_analysis = orchestrator.process_llm(requirement=item['Primary Text'], count=requirement_count)\n",
    "        #result = feedback_loop(result_analysis, EVAL_PROMPT, WORKER_PROMPT)\n",
    "        #final_result.append(feedback_loop(result_analysis, EVAL_PROMPT, WORKER_PROMPT))\n",
    "        #requirement_count=requirement_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b238072f-18f6-4e63-ba08-98a2be586de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "unpack={}\n",
    "\n",
    "llm_generator = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0,\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "llm_eval = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0,\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "def _format_prompt_worker(template: str,  **kwargs) -> str:\n",
    "    \"\"\"Format a prompt template with variables.\"\"\"\n",
    "    try:\n",
    "        return template.format(**kwargs)\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Missing required prompt variable: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a08b8b57-9f3b-4f9a-82c3-18f327da42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_case(context: str, prompt: str, feedback: str = \"\") -> tuple[str, str]:\n",
    "    \n",
    "    # full_prompt = f\"{prompt}\\n{feedback}\\n\" if feedback else f\"{prompt}\\n\"\n",
    "    \n",
    "    print(f\"*************** Generating Test case **********************\")\n",
    "    \n",
    "    memory_generate = ConversationBufferWindowMemory(k=10)\n",
    "    conversation_generate = ConversationChain(\n",
    "                    llm=llm_generator,\n",
    "                    memory=memory_generate\n",
    "    )\n",
    "    # raw_documents = retrieve_documents(context,client)\n",
    "    # documents = clean_text(raw_documents)\n",
    "    \n",
    "    if feedback:\n",
    "        worker_input = (f\"{feedback}\\n{FEEDBACK_PROMPT_WORKER}\")\n",
    "        print(\"************ Rewriting test cases as per feedback provided **************\")\n",
    "    else:\n",
    "        full_prompt = f\"{prompt}\\n\"\n",
    "        worker_input = _format_prompt_worker(\n",
    "                    full_prompt,\n",
    "                    context_requirement=context,\n",
    "                    **unpack\n",
    "        )\n",
    "    \n",
    "    #pprint(f\"******************* TC generation prompt\\n{worker_input}\\n\")\n",
    "        \n",
    "    worker_response = conversation_generate.invoke(worker_input)\n",
    "    #pprint(worker_response)\n",
    "    thoughts = extract_xml(worker_response['response'], \"thoughts\") \n",
    "    test_cases = extract_xml(worker_response['response'], \"test_cases\")\n",
    "    print(f\"====== Thought ======\\n{thoughts}\")\n",
    "    print(f\"====== Test cases====\\n{test_cases}\\n\")\n",
    "    memory_generate.save_context({\"thoughts\": feedback}, {\"test_cases\": test_cases})\n",
    "\n",
    "    return test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6e2a359-898e-43e4-9c53-38597b1edc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_case(context: str, prompt: str, test_cases: str, feedback: str = \"\") -> tuple[str, str]:\n",
    "    \"\"\"Evaluate if a solution meets requirements.\"\"\"\n",
    "    \n",
    "    memory_eval = ConversationBufferWindowMemory(k=10)\n",
    "    conversation_eval = ConversationChain(\n",
    "                    llm=llm_eval,\n",
    "                    memory=memory_eval\n",
    "    )\n",
    "    if feedback:\n",
    "        eval_input = (f\"{test_cases}\\n{FEEDBACK_PROMPT_EVAL}\")\n",
    "        print(\"************ Evaluating test cases Again **************\")\n",
    "    \n",
    "    else:\n",
    "        full_prompt = f\"{prompt}\\n\"\n",
    "        print(\"************** Evaluating Test Case ****************\")\n",
    "        eval_input = _format_prompt_worker(\n",
    "                    full_prompt,\n",
    "                    Understanding=context,\n",
    "                    test_cases=test_cases,\n",
    "                    **unpack\n",
    "        )\n",
    "    #pprint(f\"******************* TC evaluation prompt\\n{eval_input}\\n\")\n",
    "    \n",
    "    eval_response = conversation_eval.invoke(eval_input)\n",
    "    evaluation = extract_xml(eval_response['response'], \"evaluation\")\n",
    "    feedback = extract_xml(eval_response['response'], \"feedback\")\n",
    "    #pprint(worker_response)\n",
    "              \n",
    "    print(f\"\\n=== Eval RESULT ===\\n{evaluation}\\n{feedback}\")\n",
    "    memory_eval.save_context({\"test cases\": test_cases}, {\"feedback\": feedback})\n",
    "    return evaluation, feedback\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "827aa170-3e04-402a-ab11-c0a91b5f2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_loop(context: str, evaluator_prompt: str, generator_prompt: str) -> list[dict]:\n",
    "    \"\"\"Keep generating and evaluating until requirements are met.\"\"\"\n",
    "    memory = []\n",
    "    chain_of_thought = []\n",
    "    \n",
    "    test_cases = generate_test_case(context, generator_prompt)\n",
    "    memory.append(test_cases)\n",
    "    feedback= \"\"\n",
    "    \n",
    "    max_iteration = 4\n",
    "    for i in range(max_iteration):\n",
    "        #print(f\"\\n========================= iteration for evaluation {i+1} ==========================\\n\")\n",
    "        evaluation, feedback = evaluate_test_case(context, evaluator_prompt, test_cases, feedback=feedback)\n",
    "        if evaluation.strip() == \"PASS\":\n",
    "            test_cases = [iterator_str.strip() for iterator_str in test_cases.split(\"\\n\\n\") if iterator_str.strip()]\n",
    "            print(test_cases)\n",
    "            return test_cases\n",
    "            \n",
    "        # feedback = \"\\n\".join([*[f\"- {m}\" for m in memory],\n",
    "        #     f\"\\nFeedback: {feedback}\"\n",
    "        # ])\n",
    "        #print(context_join)\n",
    "        \n",
    "        test_cases = generate_test_case(context, generator_prompt, feedback=feedback)\n",
    "        memory.append(test_cases)\n",
    "        chain_of_thought.append({\"test cases\": test_cases})\n",
    "    return chain_of_thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9db5f9-3341-4a1f-9504-c41ed2fa4d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Orchestrator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m orchestrator \u001b[38;5;241m=\u001b[39m \u001b[43mOrchestrator\u001b[49m(\n\u001b[0;32m      2\u001b[0m     orchestrator_prompt\u001b[38;5;241m=\u001b[39mORCHESTRATOR_PROMPT\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      5\u001b[0m requirement_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m final_result \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Orchestrator' is not defined"
     ]
    }
   ],
   "source": [
    "orchestrator = Orchestrator(\n",
    "    orchestrator_prompt=ORCHESTRATOR_PROMPT\n",
    ")\n",
    "\n",
    "requirement_count = 0\n",
    "final_result = []\n",
    "for item in sub_req:\n",
    "    if item['Artifact Type'] == 'SYS Requirement':\n",
    "        print(f\"*********** Understanding context of Requirement {item['id']} and generating Test scenarios to validate requirement **************\")\n",
    "        result_analysis = orchestrator.process_llm(requirement=item['Primary Text'], count=requirement_count)\n",
    "        #result = feedback_loop(result_analysis, EVAL_PROMPT, WORKER_PROMPT)\n",
    "        final_result.append(feedback_loop(result_analysis, EVAL_PROMPT, WORKER_PROMPT))\n",
    "        requirement_count=requirement_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61726805-2925-48c8-a76b-ea2eee85f22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Test Case ID: 1\\nObjective: To verify the ECU's output for different steering wheel angle inputs within the effective range (±180°)\\nTest Design Technique: Equivalence Partitioning\\nPre-conditions: ECU is initialized and calibrated\\nPost-conditions: ECU's output is within the expected range\\nSteps to Execute:\\n1. Set steering wheel angle to -180° and measure ECU's output\\n2. Set steering wheel angle to -90° and measure ECU's output\\n3. Set steering wheel angle to 0° and measure ECU's output\\n4. Set steering wheel angle to 90° and measure ECU's output\\n5. Set steering wheel angle to 180° and measure ECU's output\\nExpected Results: ECU's output is within the expected range for each steering wheel angle input\",\n",
       "  \"Test Case ID: 2\\nObjective: To verify the ECU's output for boundary values of steering wheel angle\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: ECU is initialized and calibrated\\nPost-conditions: ECU's output is within the expected range\\nSteps to Execute:\\n1. Set steering wheel angle to -179° and measure ECU's output\\n2. Set steering wheel angle to -1° and measure ECU's output\\n3. Set steering wheel angle to 179° and measure ECU's output\\n4. Set steering wheel angle to 181° (out-of-range) and measure ECU's output\\nExpected Results: ECU's output is within the expected range for in-range inputs and errors out for out-of-range inputs\",\n",
       "  \"Test Case ID: 3\\nObjective: To verify the ECU's output for different steering torque input values\\nTest Design Technique: Equivalence Partitioning\\nPre-conditions: ECU is initialized and calibrated\\nPost-conditions: ECU's output is within the expected range\\nSteps to Execute:\\n1. Set steering torque to 1Nm and measure ECU's output\\n2. Set steering torque to 7.5Nm and measure ECU's output\\n3. Set steering torque to 15Nm and measure ECU's output\\nExpected Results: ECU's output is within the expected range for each steering torque input value\",\n",
       "  \"Test Case ID: 4\\nObjective: To verify the ECU's output for different turning radius input values\\nTest Design Technique: Equivalence Partitioning\\nPre-conditions: ECU is initialized and calibrated\\nPost-conditions: ECU's output is within the expected range\\nSteps to Execute:\\n1. Set turning radius to 5m and measure ECU's output\\n2. Set turning radius to 10m and measure ECU's output\\n3. Set turning radius to 15m and measure ECU's output\\nExpected Results: ECU's output is within the expected range for each turning radius input value\",\n",
       "  \"Test Case ID: 5\\nObjective: To verify the ECU's output for different vehicle speed input values\\nTest Design Technique: Equivalence Partitioning\\nPre-conditions: ECU is initialized and calibrated\\nPost-conditions: ECU's output is within the expected range\\nSteps to Execute:\\n1. Set vehicle speed to 1 km/h and measure ECU's output\\n2. Set vehicle speed to 50 km/h and measure ECU's output\\n3. Set vehicle speed to 199 km/h and measure ECU's output\\nExpected Results: ECU's output is within the expected range for each vehicle speed input value\",\n",
       "  \"Test Case ID: 6\\nObjective: To verify the ECU's behavior when multiple inputs are changed simultaneously\\nTest Design Technique: State Transition\\nPre-conditions: ECU is initialized and calibrated\\nPost-conditions: ECU's output is within the expected range\\nSteps to Execute:\\n1. Set steering wheel angle to 90° and vehicle speed to 50 km/h, and measure ECU's output\\n2. Set steering wheel angle to 0° and vehicle speed to 100 km/h, and measure ECU's output\\n3. Set steering wheel angle to -90° and vehicle speed to 20 km/h, and measure ECU's output\\nExpected Results: ECU's output is within the expected range for each combination of inputs\",\n",
       "  \"Test Case ID: 7\\nObjective: To verify the ECU's output for different combinations of steering torque and turning radius inputs\\nTest Design Technique: Pairwise\\nPre-conditions: ECU is initialized and calibrated\\nPost-conditions: ECU's output is within the expected range\\nSteps to Execute:\\n1. Set steering torque to 1Nm and turning radius to 5m, and measure ECU's output\\n2. Set steering torque to 7.5Nm and turning radius to 10m, and measure ECU's output\\n3. Set steering torque to 15Nm and turning radius to 15m, and measure ECU's output\\nExpected Results: ECU's output is within the expected range for each combination of inputs\",\n",
       "  \"Test Case ID: 8\\nObjective: To verify the ECU's response to invalid or erroneous input values\\nTest Design Technique: Error Guessing\\nPre-conditions: ECU is initialized and calibrated\\nPost-conditions: ECU's output is an error message or within the expected range\\nSteps to Execute:\\n1. Set steering wheel angle to 181° (out-of-range) and measure ECU's output\\n2. Set steering torque to -1Nm (invalid) and measure ECU's output\\n3. Set turning radius to 0m (invalid) and measure ECU's output\\nExpected Results: ECU's output is an error message for invalid inputs and within the expected range for valid inputs\"],\n",
       " [\"Test Case ID: 1\\nObjective: To verify the system's behavior during gentle turns\\nTest Design Technique: Equivalence Partitioning\\nPre-conditions: Vehicle speed: 50 km/h, Steering wheel angle: 30°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 50 km/h\\n2. Set steering wheel angle to 30°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 2\\nObjective: To verify the system's behavior during high-speed driving\\nTest Design Technique: Equivalence Partitioning\\nPre-conditions: Vehicle speed: 120 km/h, Steering wheel angle: 0°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 120 km/h\\n2. Set steering wheel angle to 0°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 3\\nObjective: To verify the system's behavior during aggressive maneuvers\\nTest Design Technique: Equivalence Partitioning\\nPre-conditions: Vehicle speed: 80 km/h, Steering wheel angle: 90°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 80 km/h\\n2. Set steering wheel angle to 90°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 4\\nObjective: To verify the system's behavior during low-speed maneuvers\\nTest Design Technique: Equivalence Partitioning\\nPre-conditions: Vehicle speed: 20 km/h, Steering wheel angle: 45°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 20 km/h\\n2. Set steering wheel angle to 45°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 5\\nObjective: To verify the system's behavior during sharp turns (±180°)\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: Vehicle speed: 50 km/h, Steering wheel angle: 179°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 50 km/h\\n2. Set steering wheel angle to 179°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 6\\nObjective: To verify the system's behavior during high-speed turns (±180°)\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: Vehicle speed: 120 km/h, Steering wheel angle: -179°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 120 km/h\\n2. Set steering wheel angle to -179°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 7\\nObjective: To verify the system's behavior during aggressive maneuvers (±450°)\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: Vehicle speed: 80 km/h, Steering wheel angle: 449°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 80 km/h\\n2. Set steering wheel angle to 449°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 8\\nObjective: To verify the system's behavior during low-speed maneuvers (±450°)\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: Vehicle speed: 20 km/h, Steering wheel angle: -449°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 20 km/h\\n2. Set steering wheel angle to -449°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 9\\nObjective: To verify the system's behavior at vehicle speed boundary (0 km/h)\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: Vehicle speed: 0 km/h, Steering wheel angle: 0°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 0 km/h\\n2. Set steering wheel angle to 0°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 10\\nObjective: To verify the system's behavior at maximum vehicle speed\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: Vehicle speed: maximum speed, Steering wheel angle: 0°\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to maximum speed\\n2. Set steering wheel angle to 0°\\n3. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 11\\nObjective: To verify the system's behavior at assistive torque boundary (1Nm)\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: Vehicle speed: 50 km/h, Steering wheel angle: 30°, Assistive torque: 1Nm\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 50 km/h\\n2. Set steering wheel angle to 30°\\n3. Set assistive torque to 1Nm\\n4. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\",\n",
       "  \"Test Case ID: 12\\nObjective: To verify the system's behavior at assistive torque boundary (15Nm)\\nTest Design Technique: Boundary Value Analysis\\nPre-conditions: Vehicle speed: 50 km/h, Steering wheel angle: 30°, Assistive torque: 15Nm\\nPost-conditions: System provides assistive torque within the expected range\\nSteps to Execute: \\n1. Initialize vehicle speed to 50 km/h\\n2. Set steering wheel angle to 30°\\n3. Set assistive torque to 15Nm\\n4. Measure assistive torque provided by the system\\nExpected Results: Assistive torque is within the expected range\"]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7460d16d-da25-4ea4-bb04-e3a74e2a32ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case ID: 1\n",
      " Expected results: ECU's output is within the expected range for each steering wheel angle input\n",
      "\n",
      "Test case ID: 2\n",
      " Expected results: ECU's output is within the expected range for in-range inputs and errors out for out-of-range inputs\n",
      "\n",
      "Test case ID: 3\n",
      " Expected results: ECU's output is within the expected range for each steering torque input value\n",
      "\n",
      "Test case ID: 4\n",
      " Expected results: ECU's output is within the expected range for each turning radius input value\n",
      "\n",
      "Test case ID: 5\n",
      " Expected results: ECU's output is within the expected range for each vehicle speed input value\n",
      "\n",
      "Test case ID: 6\n",
      " Expected results: ECU's output is within the expected range for each combination of inputs\n",
      "\n",
      "Test case ID: 7\n",
      " Expected results: ECU's output is within the expected range for each combination of inputs\n",
      "\n",
      "Test case ID: 8\n",
      " Expected results: ECU's output is an error message for invalid inputs and within the expected range for valid inputs\n",
      "\n",
      "Test case ID: 1\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 2\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 3\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 4\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 5\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 6\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 7\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 8\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 9\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 10\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 11\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n",
      "Test case ID: 12\n",
      " Expected results: Assistive torque is within the expected range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # for item in final_result:\n",
    "    #     requirement_covered = item.get(\"Requirement Covered\", \"N/A\")  # Default to \"N/A\" if key is missing\n",
    "    #     buffer_testcase = item.get(\"Test Cases\", \"\")\n",
    "for set_of_cases in final_result:\n",
    "     for case in set_of_cases:\n",
    "        lines = [line.strip() for line in case.split(\"\\n\") if line.strip()]\n",
    "        test_case_id = next(\n",
    "            (line.split(\":\", 1)[1].strip() for line in lines if line.startswith(\"Test Case ID\")), \"N/A\")\n",
    "        objective = next((line.split(\":\", 1)[1].strip() for line in lines if line.startswith(\"Objective\")),\n",
    "                         \"N/A\")\n",
    "        design_technique = next(\n",
    "            (line.split(\":\", 1)[1].strip() for line in lines if line.startswith(\"Test Design Technique\")),\n",
    "            \"N/A\")\n",
    "        pre_conditions = next(\n",
    "            (line.split(\":\", 1)[1].strip() for line in lines if line.startswith(\"Pre-conditions\")), \"N/A\")\n",
    "        post_conditions = next(\n",
    "            (line.split(\":\", 1)[1].strip() for line in lines if line.startswith(\"Post-conditions\")), \"N/A\")\n",
    "        steps_start = next((i for i, line in enumerate(lines) if line.startswith(\"Steps to Execute\")),\n",
    "                           len(lines))\n",
    "        results_start = next((i for i, line in enumerate(lines) if line.startswith(\"Expected Results\")),\n",
    "                             len(lines))\n",
    "    \n",
    "        steps = \"\\n\".join(lines[steps_start + 1:results_start]).strip() if steps_start < len(lines) else \"N/A\"\n",
    "        expected_results = next(\n",
    "            (line.split(\":\", 1)[1].strip() for line in lines if line.startswith(\"Expected Results\")), \"N/A\")\n",
    "    \n",
    "        print(f\"Test case ID: {test_case_id}\\n Expected results: {expected_results}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d41bab36-4619-42c7-b232-0a319c1d0eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.13\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\LJO2KOR\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: embedchain, langchain-community, langchain-tools\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b63ed-9d67-4562-bfd9-641fd0a9f9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
